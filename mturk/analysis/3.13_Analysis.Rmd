---
title: "3.13_Analysis"
author: "Emmi Russo"
date: "3/16/2018"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyboot)
library(lme4)

theme_set(theme_classic(base_size = 14))
```

```{r}
data <- read_csv("../data/3.13_data.csv")

nwords <- function(string, pseudo=F){
  string = gsub("[^[:alpha:][:space:]]", "", string)
  ifelse( pseudo, 
          pattern <- "\\S+", 
          pattern <- "[[:alpha:]]+" 
        )
  str_count(string, pattern)
}

data <- data %>%
  mutate(ul = nwords(utterance))

ac_info <- data %>%
  group_by(subj, trial) %>%
  distinct(.,passed_ac) %>%
  group_by(subj) %>%
  summarise(num_ac_passed = sum(passed_ac), 
            percent_ac_passed = num_ac_passed/n() * 100)

data_with_ac_info <- data %>%
  left_join(ac_info, by="subj")

# Throw out the rude people who didn't pay attention
data <- data_with_ac_info %>%
  filter(percent_ac_passed >= 95)

ggplot(ac_info, aes(x=num_ac_passed, stat="count")) + geom_bar()

# remove crappy utterance :( - shouldn't make a difference bc not test utterance 
data <- data %>%
  filter(speaker != "MOM")


# error pos data
error_pos_info <- read_csv("../error_pos_data.csv")

# add in error positions
data <- data %>%
  left_join(., error_pos_info)

single_subj_data <- comparison_data %>%
  filter(subj == 1)

ggplot(data, aes(x = log(word_response_time), fill = speaker)) +
  xlim(0, 1000) +
  geom_histogram()

comparison_data <- data %>%
  filter(is_test_utterance & word_response_time < 1000 & word_response_time > 150) %>%
  group_by(subj, trial, version, utterance_in_exchange) %>%
  #filter(error_position >= 3) %>%
  mutate(centered_pos = 1:n()-error_position)

ggplot(comparison_data, aes(x = centered_pos, y = word_response_time, fill = version)) +
  geom_smooth(method="loess") +
  facet_wrap(~trial)

ggplot(comparison_data, aes(x = centered_pos, y = log(word_response_time), fill = version)) +
  geom_smooth() +
  geom_vline(xintercept = 0) +
  xlim(-1, 5) +
  facet_wrap(~trial)

g_first_subjs <- data %>%
  filter(true_display_order == 1 & version == "g") %>%
  distinct(subj) %>%
  mutate(order="g_first")

u_first_subjs <- data %>%
  filter(true_display_order == 1 & version == "u") %>%
  distinct(subj) %>%
  mutate(order="u_first")

data <- data %>%
  right_join(full_join(g_first_subjs, u_first_subjs))
```

```{r}
## April 16th code

#check whether RTs are normally distributed
data %>%
  select(word_response_time) %>%
  filter(word_response_time > 0 & word_response_time < 5000) %>%
  mutate(log_rt = log(word_response_time)) %>%
  gather(measure, value, word_response_time, log_rt) %>%
  ggplot(aes(x = value)) + 
  facet_wrap(~ measure, scales = "free") +
  geom_histogram()

cutoffs <- data %>%
  filter(word_response_time > 0) %>%
  mutate(log_rt = log(word_response_time)) %>%
  summarise(sd = sd(log_rt),
            mean = mean(log_rt))

cutoff_data <- data %>%
  filter(word_response_time > 0) %>%
  mutate(log_rt = log(word_response_time)) %>%
  mutate(log_rt = if_else(log_rt > cutoffs$mean + 2.5 * cutoffs$sd,
                          as.numeric(NA), if_else(
                            log_rt <  cutoffs$mean - 2.5 * cutoffs$sd,
                            as.numeric(NA), log_rt)))

#How much data did we lose?
cutoff_data %>%
  summarise(na_pct = mean(is.na(log_rt))) %>%
  pull(na_pct)

#Filter down to just the relevant data
comparison_data <- cutoff_data %>%
  filter(is_test_utterance) %>%
  group_by(version, subj, trial, utterance_in_exchange) %>%
  mutate(centered_pos = 1:n()-error_position)


aggregate_data <- comparison_data %>%
  #filter(abs(centered_pos) <= 3) %>% # This seems not to matter
  mutate(word_length = 1,#nchar(gsub("[^A-Za-z]+","",stimulus)),
         rt_per_char = exp(log_rt) / word_length) %>%
  mutate(pos = if_else(centered_pos < 0, "before",
                       if_else(centered_pos > 0, "after", "during"))) %>%
  mutate(pos = factor(pos, levels = c("before", "during", "after"))) %>%
  group_by(version, pos, trial, subj, utterance_in_exchange, 
            true_display_order) %>%
   summarise(rt_per_char = mean(rt_per_char), na.rm = T)

char_model <- lmer(rt_per_char ~ version * pos + 
                     true_display_order + utterance_in_exchange  +
                     (pos + version| subj) + 
                     (pos + version| trial),
     data = aggregate_data) 

summary(char_model)

# Does the model accord with the data?
predicted_data <- aggregate_data %>%
  filter(!is.na(log_rt_per_char)) %>%
  ungroup() %>%
  mutate(predicted = predict(char_model, re.form = NA))

cor.test(predicted_data$predicted, predicted_data$log_rt_per_char)

plot_data <- aggregate_data %>%
  group_by(version, pos, subj, trial) %>%
  summarise(rt_per_char = mean(rt_per_char, na.rm = T)) %>%
  summarise(rt_per_char = mean(rt_per_char, na.rm = T)) %>%
  summarise(sem = sqrt(var(rt_per_char, na.rm = T) / 
                         sum(!is.na(rt_per_char))),
            empirical_stat = mean(rt_per_char, na.rm = T)) %>%
  mutate(ci_upper = empirical_stat + sem, ci_lower = empirical_stat - sem)

ggplot(plot_data, aes(x = pos, y = empirical_stat, color = version)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                      position = position_dodge(.5))
```

```{r}
comparison_data <- data %>%
  filter(is_test_utterance & word_response_time < 1000 & word_response_time > 150) %>%
  group_by(subj, trial, version, utterance_in_exchange) %>%
  mutate(centered_pos = 1:n()-error_position)

ggplot(data %>% filter(is_test_utterance == F), aes(y = word_response_time, x = word_in_utterance, fill=version)) +
  geom_smooth(method="loess") +
  coord_cartesian(xlim = c(1, 10)) + theme_classic() + facet_wrap(~order)

ggplot(comparison_data, aes(y = word_response_time, x = centered_pos, fill=version)) +
  geom_smooth(method="loess") +
  coord_cartesian(xlim = c(-5, 5)) + theme_classic() + facet_grid(~order)

ggplot(comparison_data, aes(y = word_response_time, x = centered_pos, fill = version)) +
  geom_smooth(method="loess") +
  facet_wrap(~error_position)  
  
  coord_cartesian(xlim = c(-1, 5)) +
  facet_wrap(~trial)

# check data size for u and g versions actually seen
sanity_check <- data %>%
  filter(is_test_utterance) %>%
  group_by(subj, trial, kid) %>%
  distinct(., kid,version) %>%
  group_by(subj, kid) %>%
  summarise(n_g = sum(version == "g"), n_u = sum(version == "u"))

total_stats <- sanity_check %>%
  summarise(total_g = sum(n_g), total_u = sum(n_u))


lmer(log(word_response_time) ~ version + (1|subj), data = comparison_data) %>%
  summary()

comparison_data %>%
  filter(centered_pos == 2) %>%
  group_by(version, order, trial, subj) %>%
  summarise(time = mean(word_response_time)) %>%
  summarise(time = mean(time)) %>%
  summarise(sd = sd(time), mean = mean(time))

```